\documentclass[12pt,twoside,abbrevs,msc,ai,notimes,logo,sansheadings]{infthesis}

% Packages
\usepackage{graphicx}
\usepackage{abbrevs}
\usepackage{acronym}
% Will use listings instead for now. minted isn't included in the ubuntu texlive version. \usepackage{minted}
\usepackage{multirow}

% Added packages
\usepackage{cite}
\usepackage{listings}
\usepackage{hyperref} % for \url
\usepackage{amstext} % for \text

% only needed for \usepackage{fancyvrb}. \renewcommand\theFancyVerbLine{\normalsize\arabic{FancyVerbLine}}

% Added config
\setlength{\parskip}{0pt plus12pt minus4pt}
\raggedbottom

% Project Details
\title{Parallelising Plan Recognition}
\author{Chris Swetenham}
\course{MSc Artificial Intelligence}
\project{Dissertation}

\submityear{2012}
\graduationdate{November 2012}
\date{\today}

\input{sections/misc/i_acronyms}
\input{sections/misc/ii_abstract}

% Extra Package Commands

\begin{document}
  \begin{preliminary}
    % Title Page
    \maketitle

    % Preamble
    \input{sections/misc/iii_acknowledgements}
    \standarddeclaration
    %\input{sections/misc/iv_dedication} TODO?
    \tableofcontents
    \listoffigures
  \end{preliminary}

% Sides per Section (Planned)
% ---------------------------
% Title page 1
% Blank 1
% Abstract 1
% Acknowledgements 1
% Declaration 1
% Blank 1
% TOC 2
% List of Figures 1
% Blank 1
% Intro 1
% Blank 1
% Background 8
% Related Work 1
% Blank 1
% Initial Work 3
% Blank 1
% Method 0 1
% Blank 1
% Method 1 2
% Method 2 3
% Blank 1
% Method 3 4
% Method 4 2
% Analysis 3
% Blank 1
% Conclusion 1
% Bibliography 2
% --------------
% Total 47

  
  % Chapters
  % Introduction: background to the project, previous work, exposition of relevant literature, setting of the work in the proper context.
  \input{sections/01_intro}
  \input{sections/02_background}
  \input{sections/03_related}
  % Description of the work undertaken: this may be divided into chapters describing the conceptual design work and the actual implementation separately. Any problems or difficulties and the suggested solutions should be mentioned. Alternative solutions and their evaluation should be included.
  \chapter{Initial Work}
  Before starting with the implementation of multithreading, we evaluated the existing ELEXIR codebase to detect any potential issues. We used the \emph{Memcheck} tool within the \emph{Valgrind} program on Linux to detect memory leaks which we then fixed. Valgrind dynamically translates the machine code being executed and allows its tools to insert instrumentation before the code is actually executed. Memcheck tracks memory allocations and can warn of both memory leaks and invalid memory accesses.
  
  The reference-counting was changed to use atomic incrementing and decrementing of reference counts, and this was sufficient to ensure thread safety, since threads incrementing the reference count always own at least one reference to it through the expression currently being processed. In order to verify that the changes made to the code did not break existing functionality, we added tests for the results of the algorithm on one of the domains. We also added unit tests for some of the new functionality.
  
  We considered several possible libraries for implementing multithreading. We chose the \emph{Boost Threads} library, which is part of the \emph{Boost} project, over the POSIX threading API for reasons of both convenience and portability; although the code has not yet been ported entirely to Windows, the added code was designed with this future port in mind.
  
  \chapter {Method 0 - Original Single-Threaded ELEXIR}
  
  The first method we include for comparaison is a mostly unmodified single-threaded implementation.
  
  \section {Implementation}
  
  On each new observation, the entire current list of explanations is looped over by the main thread, and a new list of explanations is generated.
  
  [TODO: code snippet]
  
  \section{Evaluation}
  \subsection{XPERIENCE Domain}
  TODO
  \subsection{Logistics Domain}
  TODO
  \section{Analysis}
  TODO
  
  \chapter {Method 1 - One Thread Per Task}
  
  As a proof of concept for multithreading the algorithm, this method spawns a new thread for each task.
  
  \section {Implementation}
  
  On each new observation,  the main thread spawns a new thread for each task. Each task processes its expressions and produces new resulting expressions. The main thread waits for all the spawned threds to complete, and collects their results, then spawns a new set of threads on the next observation.
  
  [TODO: code snippet]
  
  \section{Evaluation}
  \subsection{XPERIENCE Domain}
  TODO
  \subsection{Logistics Domain}
  TODO
  \section{Analysis}
  TODO
  
  \chapter {Method 2 - One Queue Per Thread}
  
  This method uses one queue per thread, guarded by a mutual exclusion lock.
  
  \section {Implementation}
  
  The main thread creates a queue for each worker thread, then spawns the threads. On each new observation, the main thread partitions the work evenly between the worker thread queues, and waits for them to finish processing them, finally collecting the new explanations.
  
  TODO - Describe blocking and signalling on the queue.
  TODO - Describe detecting completion.
  TODO - Describe boost::bounded\_buffer.
  
  \section{Evaluation}
  \subsection{XPERIENCE Domain}
  TODO
  \subsection{Logistics Domain}
  TODO
  \section{Analysis}
  TODO
  
  \chapter {Method 3 - Lock-Free Work-Stealing}
  
  This method uses one lock-free queue for each worker thread. Other threads can steal from this queue if they run out of work in their own queue.
  
  \section {Implementation}
  
  TODO - Describe implementation. Insertion of memory barriers. Hazard pointers and resizing. Expected properties in terms of load-balancing.
  
  \section{Evaluation}
  \subsection{XPERIENCE Domain}
  TODO
  \subsection{Logistics Domain}
  TODO
  \section{Analysis}
  TODO
  
  \chapter {Method 4 - Single Global Queue}
  
  This method uses a single global queue of tasks, guarded by a mutual exclusion lock.
  
  \section {Implementation}
  
  The main thread adds a single empty explanation to the global queue, then spawns a worker thread for each hardware thread available. These threads all attempt to lock the queue and extract work from it. If they cannot lock the queue, they sleep until the lock becomes available. If they lock the queue and find it empty, they sleep for a fixed period of time, then try again. Once they complete the task, they lock the queue to put all the newly generated work on the queue, then resume trying to pull a task from the head of the queue.
  
  [TODO: code snippet]
  
  \section{Evaluation}
  \subsection{XPERIENCE Domain}
  TODO
  \subsection{Logistics Domain}
  TODO
  \section{Analysis}
  TODO
  
  % \input{sections/04_design}
   
  % \input{sections/05_implementation}
  
  % Analysis: results and their critical analysis should be reported, whether the results conform to expectations or otherwise and how they compare with other related work.
  
  \input{sections/06_evaluation}
  % Conclusion:
  \input{sections/07_conclusion}

  % Appendix
  \appendix

  % \input{sections/appendix/A_evaluation.tex}

  % Bibliography
  \bibliography{sections/misc/z_bib.tex}{}
  \bibliographystyle{unsrt}
\end{document}
